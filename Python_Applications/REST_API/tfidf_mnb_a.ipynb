{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Dataset\n",
    "- 0:정치, 1:경제, 2:사회, 3:생활/문화, 4:세계, 5:IT/과학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsid</th>\n",
       "      <th>oid</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>comment</th>\n",
       "      <th>likeit</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>3179706</td>\n",
       "      <td>23</td>\n",
       "      <td>조선일보</td>\n",
       "      <td>[어수웅의 르네상스人] 종이 사전을 삼킨 남자, &amp;#39;웹 사전&amp;#39;을 낳다</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[정철 카카오 웹 사전 기획자] 책 '검색, 사전을 삼키다' 펴내… 연세대에서 사전...</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2976797</td>\n",
       "      <td>20</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>中, M&amp;A로 특허 포식… 한국 미래산업 삼킨다</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>[동아일보]中, 로봇-IoT-바이오 등 M&amp;A; 규모… 올해 5월에 이미 작년 기록...</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>2620983</td>\n",
       "      <td>25</td>\n",
       "      <td>중앙일보</td>\n",
       "      <td>구글·애플 대항마…토종 앱 장터 원스토어 떴다</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>123</td>\n",
       "      <td>9</td>\n",
       "      <td>이통 3사, 네이버 손잡고 시장 40% 점유 목표| 양강 구도에 도전장…앱 생태계 ...</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       newsid  oid newspaper                                          title  \\\n",
       "2324  3179706   23      조선일보  [어수웅의 르네상스人] 종이 사전을 삼킨 남자, &#39;웹 사전&#39;을 낳다   \n",
       "2325  2976797   20      동아일보                     中, M&A로 특허 포식… 한국 미래산업 삼킨다   \n",
       "2326  2620983   25      중앙일보                      구글·애플 대항마…토종 앱 장터 원스토어 떴다   \n",
       "\n",
       "                                                   link  comment  likeit  \\\n",
       "2324  http://news.naver.com/main/read.nhn?mode=LSD&m...        0       2   \n",
       "2325  http://news.naver.com/main/read.nhn?mode=LSD&m...       13       9   \n",
       "2326  http://news.naver.com/main/read.nhn?mode=LSD&m...      123       9   \n",
       "\n",
       "                                                content        date  category  \n",
       "2324  [정철 카카오 웹 사전 기획자] 책 '검색, 사전을 삼키다' 펴내… 연세대에서 사전...  2016-06-01         5  \n",
       "2325  [동아일보]中, 로봇-IoT-바이오 등 M&A; 규모… 올해 5월에 이미 작년 기록...  2016-06-01         5  \n",
       "2326  이통 3사, 네이버 손잡고 시장 40% 점유 목표| 양강 구도에 도전장…앱 생태계 ...  2016-06-01         5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.read_pickle(\"article_2016-06-01.plk\")\n",
    "print(len(article_df))\n",
    "article_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2094, 233, 2094, 233)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(article_df.content, article_df.category,\\\n",
    "                                                    test_size=0.1, random_state=1)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = Twitter()\n",
    "def tokenize_pos(doc):\n",
    "    return [\"/\".join(t) for t in pos_tagger.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize_pos)),\n",
    "    ('clf',MultinomialNB(alpha=0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix, Classfication Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  3,  1,  2,  0],\n",
       "       [ 1, 36,  0,  3,  0,  1],\n",
       "       [ 1,  4, 74,  4,  0,  0],\n",
       "       [ 0,  0,  1, 20,  0,  0],\n",
       "       [ 1,  1,  0,  0, 27,  0],\n",
       "       [ 0,  1,  1,  0,  0, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.87      0.90        46\n",
      "          1       0.86      0.88      0.87        41\n",
      "          2       0.94      0.89      0.91        83\n",
      "          3       0.71      0.95      0.82        21\n",
      "          4       0.93      0.93      0.93        29\n",
      "          5       0.92      0.85      0.88        13\n",
      "\n",
      "avg / total       0.90      0.89      0.89       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "X_test[0][:50], X_test[1][:50], X_test[2][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict([X_test[0], X_test[1], X_test[2]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dict = {\n",
    "    0:\"정치\", \n",
    "    1:\"경제\", \n",
    "    2:\"사회\", \n",
    "    3:\"생활/문화\", \n",
    "    4:\"세계\", \n",
    "    5:\"IT/과학\",\n",
    "}\n",
    "\n",
    "for idx, category in enumerate(result):\n",
    "    print(classification_dict[category], \"-\", X_test[idx][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save and Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"classification.plk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = pickle.load(open(\"classification.plk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"네이버와 카카오는 드론 기술 발전에 주력\"\n",
    "str2 = \"요즘 환율과 주가는 예측이 불가\"\n",
    "load_model.predict([str1, str2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dict[load_model.predict([str1])[0]],\\\n",
    "classification_dict[load_model.predict([str2])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.predict_proba([str2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
